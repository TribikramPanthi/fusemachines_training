{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =  cv2.imread('./generated_train/285044.jpeg', cv2.IMREAD_COLOR)\n",
    "img.shape\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>285044.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>383736.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>771886.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>298185.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>430460.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Data  Label\n",
       "9595  285044.jpeg      4\n",
       "9596  383736.jpeg      4\n",
       "9597  771886.jpeg      4\n",
       "9598  298185.jpeg      4\n",
       "9599  430460.jpeg      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"testset.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img =  cv2.imread('./test_folder/testset/100037.jpeg', cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252 237 204]\n"
     ]
    }
   ],
   "source": [
    "pixel = img[100, 100]\n",
    "print(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img =  cv2.imread('demo-hand-written.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh_inv = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Blur the image\n",
    "blur = cv2.GaussianBlur(thresh_inv,(1,1),0)\n",
    "\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# find contours\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\n",
    "for c in contours:\n",
    "    # get the bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if w*h>1000:\n",
    "        cv2.rectangle(mask, (x, y), (x+w, y+h), (0, 0, 255), -1)\n",
    "\n",
    "res_final = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask))\n",
    "\n",
    "cv2.imshow(\"boxes\", mask)\n",
    "cv2.imshow(\"final image\", res_final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 425, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# [200, 30, 30], [255, 90, 90])\n",
    "lower_red = np.array([0,0,150], dtype = 'uint8')  # BGR-code of your lowest red\n",
    "upper_red = np.array([39,3,255], dtype = 'uint8')   # BGR-code of your highest red \n",
    "mask = cv2.inRange(img, lower_red, upper_red) \n",
    "print(mask)\n",
    "#get all non zero values\n",
    "coord=cv2.findNonZero(mask)\n",
    "print(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0, ..., 617, 617, 617]),\n",
       " array([  0,   1,   2, ..., 422, 423, 424]),\n",
       " array([2, 2, 2, ..., 2, 2, 2]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = (0,0,255)\n",
    "np.where(img ==color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 425, 3)\n",
      "original: (618, 425, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Number of Contours found = 1467\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Contours tuple must have length 2 or 3, otherwise OpenCV changed their cv2.findContours return signature yet again. Refer to OpenCV's documentation in that case",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-87a48618c476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mcnts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mgrab_contours\u001b[0;34m(cnts)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# signature yet again and I have no idea WTH is going on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         raise Exception((\"Contours tuple must have length 2 or 3, \"\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;34m\"otherwise OpenCV changed their cv2.findContours return \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;34m\"signature yet again. Refer to OpenCV's documentation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Contours tuple must have length 2 or 3, otherwise OpenCV changed their cv2.findContours return signature yet again. Refer to OpenCV's documentation in that case"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "  \n",
    "# Let's load a simple image with 3 black squares \n",
    "image = cv2.imread('./test_folder/testset/100037.jpeg') \n",
    "# cv2.waitKey(0) \n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "  \n",
    "# Grayscale \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "# Find Canny edges \n",
    "edged = cv2.Canny(gray, 30, 200) \n",
    "cv2.waitKey(0) \n",
    "# print(edged.shape)\n",
    "# print(image[:,:].shape)\n",
    "img2 = np.zeros_like(image)\n",
    "img2[:,:,0] = edged\n",
    "img2[:,:,1] = edged\n",
    "img2[:,:,2] = edged\n",
    "print(img2.shape)\n",
    "print(\"original:\", image.shape)\n",
    "print(type(image))\n",
    "# Finding Contours \n",
    "# Use a copy of the image e.g. edged.copy() \n",
    "# since findContours alters the image \n",
    "contours, hierarchy = cv2.findContours(edged,  \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "# img2 = cv2.bitwise_not(img2)\n",
    "cv2.imshow('Canny Edges After Contouring', img2) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "print(\"Number of Contours found = \" + str(len(contours))) \n",
    "  \n",
    "    \n",
    "cnts = imutils.grab_contours(contours)\n",
    "cnts1 = cnts[0]\n",
    "\n",
    "# Draw all contours \n",
    "# -1 signifies drawing all contours \n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n",
    "  \n",
    "cv2.imshow('Contours', image) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "# img1_bg = cv2.bitwise_and(image,edged)\n",
    "img1_bg = np.multiply(image, img2)\n",
    "cv2.imshow('Contour', img1_bg) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "df = pd.read_csv(\"test_folder/testset.csv\")\n",
    "# for x in df.tail(1)[\"Data\"]:\n",
    "#     a = os.path.join('./testset', x)\n",
    "#     img = cv2.imread(a)\n",
    "#     cv2.imshow('image', img)\n",
    "#     cv2.waitKey(0) \n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#     image_path = os.path.join('./generated_train',x)\n",
    "#     print(image_path)\n",
    "\n",
    "#     cv2.imwrite(image_path, img) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600795.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627152.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119963.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118264.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199420.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>285044.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>383736.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>771886.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>298185.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>430460.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Data  Label\n",
       "0     600795.jpeg     10\n",
       "1     627152.jpeg     10\n",
       "2     119963.jpeg     10\n",
       "3     118264.jpeg     10\n",
       "4     199420.jpeg     10\n",
       "...           ...    ...\n",
       "9595  285044.jpeg      4\n",
       "9596  383736.jpeg      4\n",
       "9597  771886.jpeg      4\n",
       "9598  298185.jpeg      4\n",
       "9599  430460.jpeg      4\n",
       "\n",
       "[9400 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Label']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#experiment\n",
    "import os\n",
    "import cv2\n",
    "mask3 = cv2.imread(os.path.join('./generated_train','285044.jpeg' ))\n",
    "print(type(mask3))\n",
    "df = pd.read_csv(\"testset.csv\")\n",
    "for a in df.loc[df['Label']==0]['Data']:\n",
    "    img = cv2.imread(os.path.join('./generated_train', a))\n",
    "    mask3 = cv2.bitwise_or(img, mask3, mask = None) \n",
    "#     mask3 = cv2.add(img, mask3) \n",
    "\n",
    "#     print(mask3.shape)\n",
    "cv2.imshow('image', mask3)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"invalidclusterfile.jpeg\", mask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1620\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Contours tuple must have length 2 or 3, otherwise OpenCV changed their cv2.findContours return signature yet again. Refer to OpenCV's documentation in that case",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a66df47cefc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcnts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mgrab_contours\u001b[0;34m(cnts)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# signature yet again and I have no idea WTH is going on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         raise Exception((\"Contours tuple must have length 2 or 3, \"\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;34m\"otherwise OpenCV changed their cv2.findContours return \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;34m\"signature yet again. Refer to OpenCV's documentation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Contours tuple must have length 2 or 3, otherwise OpenCV changed their cv2.findContours return signature yet again. Refer to OpenCV's documentation in that case"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(mask3, cv2.COLOR_BGR2GRAY) \n",
    "edged = cv2.Canny(gray, 30, 200) \n",
    "cv2.waitKey(0) \n",
    "contours, hierarchy = cv2.findContours(edged,  \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "# img2 = cv2.bitwise_not(img2)\n",
    "cv2.imshow('Canny Edges After Contouring', edged) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "print(\"Number of Contours found = \" + str(len(contours))) \n",
    "  \n",
    "    \n",
    "cnts = imutils.grab_contours(contours)\n",
    "cnts1 = cnts[0]\n",
    "\n",
    "# Draw all contours \n",
    "# -1 signifies drawing all contours \n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n",
    "  \n",
    "cv2.imshow('Contours', image) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 45,  3, 23, 37, 34, 16,  5, 36, 26, 47, 27,  6, 28, 22,  1, 31,\n",
       "       43,  0, 35, 20, 33, 18, 39, 32, 21, 12, 42, 11, 29, 40, 24, 14,  8,\n",
       "        7, 38, 46, 17, 30, 41, 44, 25,  2, 19, 13,  9, 15,  4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new data based on the presence of red color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "df = pd.read_csv(\"test_folder/testset.csv\")\n",
    "def take_input(image):\n",
    "    img = cv2.imread(os.path.join('./test_folder/testset', image))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_range = np.array([0, 70, 50])\n",
    "    upper_range = np.array([10, 255, 255])\n",
    "\n",
    "    mask1 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    lower_range = np.array([170, 70, 50])\n",
    "    upper_range = np.array([100, 255, 255])\n",
    "\n",
    "    mask2 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    mask3 = cv2.bitwise_or(mask1, mask2, mask = None) \n",
    "    return img, mask3\n",
    "    #     image_path = os.path.join('./generated_test',a)\n",
    "    #     cv2.imwrite(image_path, mask3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's project these points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 425)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "img = cv2.imread('./test_folder/testset/100262.jpeg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_range = np.array([0, 70, 50])\n",
    "upper_range = np.array([10, 255, 255])\n",
    "\n",
    "mask1 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "lower_range = np.array([170, 70, 50])\n",
    "upper_range = np.array([100, 255, 255])\n",
    "\n",
    "mask2 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('mask', mask1)\n",
    "cv2.imshow('mask2', mask2)\n",
    "mask3 = cv2.bitwise_or(mask1, mask2, mask = None) \n",
    "# mask3 = np.logical_or(mask, mask2)\n",
    "cv2.imshow('mask3', mask3)\n",
    "print(mask3.shape)\n",
    "\n",
    "# print(\"mask\")\n",
    "# if ((mask==0)|(mask ==1)).all():\n",
    "#     print(\"True\")\n",
    "# else:\n",
    "#     print(\"false\")\n",
    "    \n",
    "# print(mask)\n",
    "\n",
    "while(True):\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n",
      "(618, 425, 3)\n"
     ]
    }
   ],
   "source": [
    "for a in df.head(35)['Data']:\n",
    "    img = cv2.imread(os.path.join('./testset', a))\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Thres', img) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(x, (11, 11), 0)\n",
    "cv2.imshow('Contours', blurred) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imshow('Thres', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(mask3, cv2.COLOR_BGR2GRAY) \n",
    "edged = cv2.Canny(x, 30, 200) \n",
    "cv2.waitKey(0) \n",
    "contours, hierarchy = cv2.findContours(edged,  \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "# img2 = cv2.bitwise_not(img2)\n",
    "cv2.imshow('Canny Edges After Contouring', edged) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinate mapping\n",
    "\n",
    "127,101\n",
    "\n",
    "214,101\n",
    "\n",
    "299,101\n",
    "\n",
    "17,139\n",
    "\n",
    "17,181\n",
    "\n",
    "17, 215\n",
    "\n",
    "14,247\n",
    "\n",
    "14,283\n",
    "\n",
    "13,319\n",
    "\n",
    "13,357\n",
    "\n",
    "13,389\n",
    "\n",
    "15,426\n",
    "\n",
    "16,463\n",
    "\n",
    "20,501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = x\n",
    "\n",
    "\n",
    "def predict(test_img, threshold=100):\n",
    "    count_threshold = 0\n",
    "    label = 0\n",
    "    count = np.count_nonzero(test_img[95:139,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 1\n",
    "    count = np.count_nonzero(test_img[139:181, 17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 2\n",
    "\n",
    "    count = np.count_nonzero(test_img[181:215,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 3\n",
    "    count = np.count_nonzero(test_img[215:247,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 4\n",
    "    count = np.count_nonzero(test_img[247:283,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 5\n",
    "    count =  np.count_nonzero(test_img[283:319,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 6\n",
    "    count =  np.count_nonzero(test_img[319:375,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 7\n",
    "    count =  np.count_nonzero(test_img[360:395,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 8\n",
    "    count =  np.count_nonzero(test_img[395:426,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 9\n",
    "    count =  np.count_nonzero(test_img[426:463,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 10\n",
    "    count =  np.count_nonzero(test_img[463:501,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 11\n",
    "    count =  np.count_nonzero(test_img[501:542,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 12\n",
    "    count =  np.count_nonzero(test_img[95:139,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 13\n",
    "    count =  np.count_nonzero(test_img[139:181,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 14\n",
    "    count =  np.count_nonzero(test_img[181:215, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 15\n",
    "    count =  np.count_nonzero(test_img[215:247, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 16\n",
    "    count =  np.count_nonzero(test_img[247:283, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 17\n",
    "    count =  np.count_nonzero(test_img[283:319,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 18\n",
    "    count =  np.count_nonzero(test_img[319:360,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 19\n",
    "    count =  np.count_nonzero(test_img[360:395,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 20\n",
    "    count =  np.count_nonzero(test_img[395:426,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 21\n",
    "    count =  np.count_nonzero(test_img[426:463,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 22\n",
    "    count =  np.count_nonzero(test_img[463:501,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 23\n",
    "    count =  np.count_nonzero(test_img[501:542,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 24\n",
    "    count =  np.count_nonzero(test_img[95:139,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 25\n",
    "    count =  np.count_nonzero(test_img[139:181,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 26\n",
    "    count =  np.count_nonzero(test_img[181:215,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 27\n",
    "    count =  np.count_nonzero(test_img[215:247,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 28\n",
    "    count =  np.count_nonzero(test_img[247:283,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 29\n",
    "    count =  np.count_nonzero(test_img[283:319,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 30\n",
    "    count =  np.count_nonzero(test_img[319:360,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 31\n",
    "    count =  np.count_nonzero(test_img[360:395,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 32\n",
    "    count =  np.count_nonzero(test_img[395:426,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 33\n",
    "    count =  np.count_nonzero(test_img[426:463,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 34\n",
    "    count =  np.count_nonzero(test_img[463:501,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 35\n",
    "    count = np.count_nonzero(test_img[501:542,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 36\n",
    "    count = np.count_nonzero(test_img[95:139,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 37\n",
    "    count = np.count_nonzero(test_img[139:181,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 38\n",
    "    count =np.count_nonzero(test_img[181:215,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 39\n",
    "    count = np.count_nonzero(test_img[215:247,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 40\n",
    "    count = np.count_nonzero(test_img[247:283,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 41\n",
    "    count = np.count_nonzero(test_img[283:319,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 42\n",
    "    count = np.count_nonzero(test_img[319:360,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 43\n",
    "    count = np.count_nonzero(test_img[360:395,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 44\n",
    "    count = np.count_nonzero(test_img[395:426,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 45\n",
    "    count = np.count_nonzero(test_img[426:463,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 46\n",
    "    count = np.count_nonzero(test_img[463:501,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 47\n",
    "    return label    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632755.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496855.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155390.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265013.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496360.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>728422.jpeg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>867837.jpeg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>258941.jpeg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>274666.jpeg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>679357.jpeg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Data  Label\n",
       "0   632755.jpeg     10\n",
       "1   496855.jpeg     10\n",
       "2   155390.jpeg     10\n",
       "3   265013.jpeg     10\n",
       "4   496360.jpeg     10\n",
       "..          ...    ...\n",
       "95  728422.jpeg     45\n",
       "96  867837.jpeg     45\n",
       "97  258941.jpeg     45\n",
       "98  274666.jpeg     45\n",
       "99  679357.jpeg     45\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, mask):\n",
    "    cv2.imshow('Original', img) \n",
    "    cv2.imshow('Star', mask[:,:]) \n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, mask=take_input('274666.jpeg')\n",
    "predict(mask[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-5abf1969f21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-bfb468c359a4>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(img, mask)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Star'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img, mask=take_input('274666.jpeg')\n",
    "predict(mask[:,:])\n",
    "display(img, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_folder/testset.csv')\n",
    "\n",
    "listt = []\n",
    "for imgg in df['Data']:\n",
    "    img, mask = take_input(imgg)\n",
    "    x = predict(mask[:,:])\n",
    "    listt.append(x)\n",
    "\n",
    "df2= df.copy()\n",
    "df2['Predicted']=listt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.37      0.05        30\n",
      "           1       0.93      0.79      0.85        33\n",
      "           2       1.00      0.88      0.93        16\n",
      "           3       1.00      0.92      0.96        13\n",
      "           4       0.98      0.79      0.87        56\n",
      "           5       0.86      1.00      0.92         6\n",
      "           6       0.96      0.87      0.91        30\n",
      "           7       0.75      0.87      0.81        63\n",
      "           8       1.00      0.49      0.66        45\n",
      "           9       1.00      0.82      0.90        68\n",
      "          10       0.84      0.89      0.86        18\n",
      "          11       0.99      0.90      0.94        94\n",
      "          12       1.00      0.85      0.92        88\n",
      "          13       1.00      0.88      0.94        92\n",
      "          14       1.00      0.86      0.92        14\n",
      "          15       1.00      0.86      0.92        50\n",
      "          16       1.00      0.78      0.88        59\n",
      "          17       0.92      0.86      0.89        14\n",
      "          18       1.00      0.85      0.92        65\n",
      "          19       1.00      0.78      0.88        74\n",
      "          20       0.99      0.87      0.93        86\n",
      "          21       1.00      0.82      0.90        22\n",
      "          22       1.00      0.86      0.93        81\n",
      "          23       0.97      0.80      0.88        71\n",
      "          24       1.00      0.85      0.92        82\n",
      "          25       1.00      0.84      0.91        76\n",
      "          26       1.00      0.85      0.92        47\n",
      "          27       1.00      0.87      0.93        83\n",
      "          28       1.00      0.86      0.92       100\n",
      "          29       0.98      0.92      0.95        64\n",
      "          30       1.00      0.94      0.97        86\n",
      "          31       1.00      0.89      0.94        56\n",
      "          32       1.00      0.91      0.95        86\n",
      "          33       0.98      0.82      0.89        55\n",
      "          34       0.98      0.84      0.91        57\n",
      "          35       1.00      0.71      0.83        14\n",
      "          36       1.00      0.92      0.96        62\n",
      "          37       1.00      0.81      0.90        58\n",
      "          38       0.99      0.81      0.89        89\n",
      "          39       0.93      0.88      0.90        16\n",
      "          40       0.97      0.96      0.96        67\n",
      "          41       0.97      0.86      0.91        42\n",
      "          42       0.78      0.70      0.74        10\n",
      "          43       1.00      0.80      0.89        45\n",
      "          44       1.00      0.79      0.88        43\n",
      "          45       1.00      0.84      0.91        99\n",
      "          46       1.00      0.83      0.91        24\n",
      "          47       0.98      0.90      0.94        60\n",
      "\n",
      "    accuracy                           0.84      2609\n",
      "   macro avg       0.95      0.83      0.88      2609\n",
      "weighted avg       0.97      0.84      0.90      2609\n",
      "\n",
      "[[11  2  0 ...  0  0  1]\n",
      " [ 7 26  0 ...  0  0  0]\n",
      " [ 2  0 14 ...  0  0  0]\n",
      " ...\n",
      " [16  0  0 ... 83  0  0]\n",
      " [ 4  0  0 ...  0 20  0]\n",
      " [ 6  0  0 ...  0  0 54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(df2['Label'].values, df2['Predicted'].values))\n",
    "print(confusion_matrix(df2['Label'].values, df2['Predicted'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f66a7741390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df1 = pd.read_csv('testset.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize =(20, 7))\n",
    "df['Label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>525230.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>281668.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>183565.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>607250.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>629213.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>587975.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>420732.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>271342.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>427837.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>255361.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Data  Label\n",
       "3600  525230.jpeg      0\n",
       "3601  281668.jpeg      0\n",
       "3602  183565.jpeg      0\n",
       "3603  607250.jpeg      0\n",
       "3604  629213.jpeg      0\n",
       "...           ...    ...\n",
       "3795  587975.jpeg      0\n",
       "3796  420732.jpeg      0\n",
       "3797  271342.jpeg      0\n",
       "3798  427837.jpeg      0\n",
       "3799  255361.jpeg      0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1['Label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "df = pd.read_csv(\"test_folder/testset.csv\")\n",
    "def take_input(image):\n",
    "    img = cv2.imread(os.path.join('./test_folder/testset', image))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_range = np.array([0, 70, 50])\n",
    "    upper_range = np.array([10, 255, 255])\n",
    "\n",
    "    mask1 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    lower_range = np.array([170, 70, 50])\n",
    "    upper_range = np.array([100, 255, 255])\n",
    "\n",
    "    mask2 = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    mask3 = cv2.bitwise_or(mask1, mask2, mask = None) \n",
    "    return img, mask3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = x\n",
    "\n",
    "\n",
    "def predict(test_img, threshold=100):\n",
    "    count_threshold = 0\n",
    "    label = 0\n",
    "    count = np.count_nonzero(test_img[95:139,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 1\n",
    "    count = np.count_nonzero(test_img[139:181, 17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 2\n",
    "\n",
    "    count = np.count_nonzero(test_img[181:215,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 3\n",
    "    count = np.count_nonzero(test_img[215:247,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 4\n",
    "    count = np.count_nonzero(test_img[247:283,17:127]>threshold)    \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 5\n",
    "    count =  np.count_nonzero(test_img[283:319,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 6\n",
    "    count =  np.count_nonzero(test_img[319:375,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 7\n",
    "    count =  np.count_nonzero(test_img[360:395,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 8\n",
    "    count =  np.count_nonzero(test_img[395:426,17:127]>threshold) \n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 9\n",
    "    count =  np.count_nonzero(test_img[426:463,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 10\n",
    "    count =  np.count_nonzero(test_img[463:501,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 11\n",
    "    count =  np.count_nonzero(test_img[501:542,17:127]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 12\n",
    "    count =  np.count_nonzero(test_img[95:139,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 13\n",
    "    count =  np.count_nonzero(test_img[139:181,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 14\n",
    "    count =  np.count_nonzero(test_img[181:215, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 15\n",
    "    count =  np.count_nonzero(test_img[215:247, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 16\n",
    "    count =  np.count_nonzero(test_img[247:283, 127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 17\n",
    "    count =  np.count_nonzero(test_img[283:319,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 18\n",
    "    count =  np.count_nonzero(test_img[319:360,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 19\n",
    "    count =  np.count_nonzero(test_img[360:395,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 20\n",
    "    count =  np.count_nonzero(test_img[395:426,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 21\n",
    "    count =  np.count_nonzero(test_img[426:463,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 22\n",
    "    count =  np.count_nonzero(test_img[463:501,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 23\n",
    "    count =  np.count_nonzero(test_img[501:542,127:214]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 24\n",
    "    count =  np.count_nonzero(test_img[95:139,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 25\n",
    "    count =  np.count_nonzero(test_img[139:181,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 26\n",
    "    count =  np.count_nonzero(test_img[181:215,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 27\n",
    "    count =  np.count_nonzero(test_img[215:247,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 28\n",
    "    count =  np.count_nonzero(test_img[247:283,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 29\n",
    "    count =  np.count_nonzero(test_img[283:319,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 30\n",
    "    count =  np.count_nonzero(test_img[319:360,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 31\n",
    "    count =  np.count_nonzero(test_img[360:395,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 32\n",
    "    count =  np.count_nonzero(test_img[395:426,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 33\n",
    "    count =  np.count_nonzero(test_img[426:463,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 34\n",
    "    count =  np.count_nonzero(test_img[463:501,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 35\n",
    "    count = np.count_nonzero(test_img[501:542,214:300]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 36\n",
    "    count = np.count_nonzero(test_img[95:139,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 37\n",
    "    count = np.count_nonzero(test_img[139:181,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 38\n",
    "    count =np.count_nonzero(test_img[181:215,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 39\n",
    "    count = np.count_nonzero(test_img[215:247,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 40\n",
    "    count = np.count_nonzero(test_img[247:283,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 41\n",
    "    count = np.count_nonzero(test_img[283:319,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 42\n",
    "    count = np.count_nonzero(test_img[319:360,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 43\n",
    "    count = np.count_nonzero(test_img[360:395,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 44\n",
    "    count = np.count_nonzero(test_img[395:426,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 45\n",
    "    count = np.count_nonzero(test_img[426:463,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 46\n",
    "    count = np.count_nonzero(test_img[463:501,300:400]>threshold)\n",
    "    if count > count_threshold:\n",
    "        count_threshold = count\n",
    "        label = 47\n",
    "    return label    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, mask):\n",
    "    cv2.imshow('Original', img) \n",
    "    cv2.imshow('Star', mask[:,:]) \n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632755.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496855.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155390.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265013.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496360.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Label\n",
       "0  632755.jpeg     10\n",
       "1  496855.jpeg     10\n",
       "2  155390.jpeg     10\n",
       "3  265013.jpeg     10\n",
       "4  496360.jpeg     10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 45\n"
     ]
    }
   ],
   "source": [
    "img, mask=take_input('274666.jpeg')\n",
    "result = predict(mask[:,:])\n",
    "print(\"Predicted class\", result)\n",
    "display(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
